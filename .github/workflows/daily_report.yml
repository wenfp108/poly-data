name: Daily Heatmap & JSON Report

# æ¯å¤©åŒ—äº¬æ—¶é—´ 23:30 (UTC 15:30) è‡ªåŠ¨è¿è¡Œ
on:
  schedule:
    - cron: '30 15 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build-report:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Generate Reports
        run: |
          cat <<EOF > analyzer.py
          import os
          import json
          from datetime import datetime
          import pytz

          # 1. è®¾å®šç›®å½•
          tz = pytz.timezone('Asia/Shanghai')
          today_str = datetime.now(tz).strftime('%Y-%m-%d')
          target_dir = f"data/{today_str}"
          
          print(f"æ­£åœ¨åˆ†æç›®å½•: {target_dir}")

          if not os.path.exists(target_dir):
              print("ä»Šæ—¥æ— æ•°æ®ã€‚")
              exit(0)

          # 2. æ ¸å¿ƒèšåˆé€»è¾‘ (å»é‡ + è®¡æ•°)
          event_map = {}
          file_count = 0

          for filename in os.listdir(target_dir):
              # æ’é™¤æ‰å’±ä»¬è‡ªå·±ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶ï¼Œåªè¯»åŸå§‹æ•°æ®
              if filename.endswith(".json") and not filename.startswith("DAILY_"):
                  file_count += 1
                  filepath = os.path.join(target_dir, filename)
                  try:
                      with open(filepath, 'r') as f:
                          content = json.load(f)
                          
                          # æå–å”¯ä¸€ ID
                          meta = content.get('meta', {})
                          data = content.get('data', {})
                          event_id = meta.get('id', data.get('slug', 'unknown'))
                          
                          if event_id not in event_map:
                              event_map[event_id] = {
                                  "count": 0,
                                  "latest_data": content # é»˜è®¤å­˜è¿™ä¸ª
                              }
                          
                          event_map[event_id]["count"] += 1
                          
                          # é€»è¾‘ï¼šæ€»æ˜¯ä¿ç•™æˆäº¤é‡(Volume)æœ€å¤§çš„é‚£ä»½æ•°æ®ä½œä¸ºâ€œæœ€ç»ˆç‰ˆâ€
                          current_vol = float(data.get('volume', 0))
                          saved_vol = float(event_map[event_id]['latest_data'].get('data', {}).get('volume', 0))
                          
                          if current_vol > saved_vol:
                              event_map[event_id]['latest_data'] = content

                  except Exception as e:
                      print(f"Error reading {filename}: {e}")

          # === è¾“å‡º 1: ç”Ÿæˆ Markdown çƒ­åŠ›æˆ˜æŠ¥ (ç»™äººçœ‹) ===
          report_list = []
          # åŒæ—¶å‡†å¤‡ä¸€ä¸ªçº¯æ•°æ®åˆ—è¡¨ (ç»™ AI çœ‹)
          raw_data_list = []

          for eid, info in event_map.items():
              raw_data = info['latest_data']
              raw_data_list.append(raw_data) # æŠŠå®Œæ•´çš„åŸå§‹ JSON å¡è¿›å»

              data = raw_data.get('data', {})
              meta = raw_data.get('meta', {})
              
              # æå–èƒœç‡é€»è¾‘
              top_outcome = "N/A"
              top_prob = 0
              if 'markets' in data and len(data['markets']) > 0:
                  m = data['markets'][0]
                  try:
                      prices = json.loads(m.get('outcomePrices', '[]'))
                      outcomes = json.loads(m.get('outcomes', '[]'))
                      if prices and outcomes:
                          max_p = max(prices)
                          idx = prices.index(max_p)
                          top_outcome = outcomes[idx]
                          top_prob = float(max_p) * 100
                  except:
                      pass

              report_list.append({
                  "title": meta.get('title', data.get('title', eid)),
                  "sector": meta.get('sector_tag', 'General'),
                  "count": info['count'],
                  "volume": float(data.get('volume', 0)),
                  "prob_str": f"{top_outcome} ({top_prob:.1f}%)",
                  "url": f"https://polymarket.com/event/{eid}"
              })

          # æ’åº
          report_list.sort(key=lambda x: (x['count'], x['volume']), reverse=True)

          # å†™å…¥ Markdown
          md = f"# ğŸ“Š å…¨å¤©å€™çƒ­åŠ›æˆ˜æŠ¥ ({today_str})\n\n"
          md += f"**æ–‡ä»¶é‡‡æ ·**: {file_count} | **å»é‡äº‹ä»¶**: {len(report_list)}\n\n"
          md += "| çƒ­åº¦ | æ¿å— | äº‹ä»¶æ ‡é¢˜ | å…±è¯† | èµ„é‡‘ |\n"
          md += "| :--- | :--- | :--- | :--- | :--- |\n"

          for item in report_list:
              count = item['count']
              if count >= 20: icon = "ğŸ”¥ğŸ”¥ğŸ”¥"
              elif count >= 10: icon = "ğŸ”¥"
              elif count >= 5: icon = "â­ï¸"
              else: icon = "â„ï¸"
              vol = f"${item['volume']/1000000:.2f}M" if item['volume'] > 1000000 else f"${item['volume']/1000:.0f}k"
              md += f"| {icon} {count} | {item['sector']} | [{item['title']}]({item['url']}) | {item['prob_str']} | {vol} |\n"

          with open(f"{target_dir}/DAILY_HEATMAP_{today_str}.md", "w") as f:
              f.write(md)

          # === è¾“å‡º 2: ç”Ÿæˆ JSON æ±‡æ€»åŒ… (ç»™ AI åˆ†æç”¨) ===
          # è¿™æ˜¯ä¸€ä¸ªåŒ…å«å½“å¤©æ‰€æœ‰å»é‡ååŸå§‹æ•°æ®çš„è¶…çº§ JSON
          json_path = f"{target_dir}/DAILY_SUMMARY_{today_str}.json"
          with open(json_path, 'w') as f:
              json.dump(raw_data_list, f, indent=2)

          print(f"æˆåŠŸç”ŸæˆåŒæŠ¥è¡¨ï¼š\n1. Heatmap (Markdown)\n2. Summary (JSON, {len(raw_data_list)} items)")
          EOF

          pip install pytz
          python analyzer.py

      - name: Commit results
        run: |
          git config --global user.name "Report Bot"
          git config --global user.email "bot@github.com"
          git add data/
          git commit -m "ğŸ“Š Generate Daily Heatmap & JSON" || exit 0
          git push
